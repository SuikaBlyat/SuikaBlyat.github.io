<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>知乎专栏爬虫 2020.07.11</title>
      <link href="/zhihucrawler/"/>
      <url>/zhihucrawler/</url>
      
        <content type="html"><![CDATA[<blockquote><p>新手爬虫初体验</p></blockquote><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>因为是疫情期间在加里敦大学学的Python,代码可能不规范，功能也只是比较基础<s>或者说原始的</s>，但尚且能用hhhh</p><p>在此发表一来是记录一下自己的学习历程与成果，二来也算是抛砖引玉，若有任何疑问或者建议都可以发E-mail与本彩笔交流。</p><p>话不多说直接上代码啦</p><h1 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h1><pre><code>#import所需的各种库from selenium import webdriverfrom selenium.webdriver.chrome.options import Optionsimport bs4import timefrom openpyxl import Workbookimport requestsarticle_url_list = [] article_title_list = []  #这个好像多余了，但我懒得删掉了pages = int(input(&#39;请输入需要爬取文章页数：&#39;))author = input(&#39;请输入专栏作者：&#39;)  #注意这里不是昵称，是作者的英文id哦headers = {            &#39;origin&#39;: &#39;https://zhuanlan.zhihu.com&#39;,            &#39;referer&#39;: &#39;https://zhuanlan.zhihu.com/{}&#39;.format(author),            &#39;user-agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36&#39;}#这部分没封装启动函数是因为封装了之后crawler函数会发现driver undefined，我图省事就取消封装了，没有尝试__init__,反正能用就是hhhwb = Workbook() #创建excel工作簿ws = wb.active  #定义活动工作表ws.append([&#39;标题&#39;, &#39;简介&#39;, &#39;链接&#39;, &#39;赞同&#39;])print(&#39;_______\n正在启动浏览器&#39;)chrome_options = Options()chrome_options.add_argument(&#39;--headless&#39;)driver = webdriver.Chrome(options=chrome_options)driver.get(&#39;https://zhuanlan.zhihu.com/{}&#39;.format(author))  # 专栏地址time.sleep(2) #给点时间加载#封装滑动函数def scroll():    print(&#39;_______\n正在模拟Chrome下滑&#39;)    i = 0    while i &lt; pages:  # 当文章数量多时，        driver.execute_script(&quot;window.scrollBy(0,5000)&quot;) #滑动幅度可自行修改，5000还挺大的        time.sleep(1)        i += 1    print(&#39;_______\n模拟结束&#39;)def crawler_list():    print(&#39;_______\n正在爬取列表:\n&#39;)    res = driver.page_source    bs_res = bs4.BeautifulSoup(res, &#39;html.parser&#39;)    articles = bs_res.find_all(&#39;li&#39;, class_=&#39;ArticleItem&#39;)    for article in articles:        title = article.find_all(&#39;h3&#39;, class_=&#39;ArticleItem-Title&#39;)[0].text        article_url = article.find_all(&#39;a&#39;)[0][&#39;href&#39;]        summary = article.find(&#39;p&#39;, class_=&#39;RichContent-inner&#39;).text        vote = article.find(&#39;button&#39;, class_=&#39;Button VoteButton VoteButton--up&#39;)[&#39;aria-label&#39;]        vote = vote[2:]        article_url_list.append(article_url) #添加到URL列表方便下一个函数爬取文章内容        article_title_list.append(title) #回应开头那个多余的代码）        line = [title, summary, article_url, vote]        ws.append(line)        print(&#39;添加《{title}》到列表&#39;.format(title=title))        time.sleep(1) #可删，不过就看不到一个一个title出来了    print(&#39;_______\n列表爬取完毕\n&#39;)def crawler_article():    print(&#39;_______\n正在录入内容:\n&#39;)    for z in range(len(article_url_list)):        url_2= article_url_list[z]        r = requests.get(url_2, headers=headers)        bs_r = bs4.BeautifulSoup(r.text, &#39;html.parser&#39;)        content = bs_r.find(class_=&#39;RichText ztext Post-RichText&#39;) #需要纯文本的请在后面加.text 然后可以把下一行删掉        content = str(content)        title = bs_r.find_all(&#39;h1&#39;, class_=&#39;Post-Title&#39;)[0].text        title_short = title[:7] #截取纯数字        f = open(&#39;SourceCodes/{}.txt&#39;.format(title_short), &#39;w&#39;, encoding=&#39;utf-8&#39;)        f.write(content)        f.close()        print(&#39;已录入《{}》&#39;.format(title))def close():    wb.save(&#39;SumList.xlsx&#39;)    print(&#39;_______\n已保存文章列表&#39;)     wb.close()    driver.close()    print(&#39;_______\n驱动已关闭\nExcel已关闭\n_______&#39;)    input(&#39;\n请输入回车结束爬虫&#39;) #不在pycharm运行时像暂时不结束脚本才加的，可删def main():    scroll()    crawler_list()    crawler_article()    close()main()</code></pre>]]></content>
      
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Crawler </tag>
            
            <tag> Beginner </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>The Beginning of DDL Fighter</title>
      <link href="/ddl-fighter/"/>
      <url>/ddl-fighter/</url>
      
        <content type="html"><![CDATA[<blockquote><p>拖延有感</p></blockquote><p>很喜欢狄更斯在《挪威的森林》里说的一句话：“一个人是不是DDL Fighter从他小学怎么做暑假作业就已经决定了。”</p>]]></content>
      
      
      <categories>
          
          <category> Junkpiece </category>
          
      </categories>
      
      
        <tags>
            
            <tag> DDL fighter </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Source of Happyness</title>
      <link href="/my-source-of-happyness/"/>
      <url>/my-source-of-happyness/</url>
      
        <content type="html"><![CDATA[<blockquote><p>科普一下三种快乐物质————多巴胺、血清素、内啡肽。<br><img src="/medias/contect.png" alt></p></blockquote><p><b>多巴胺</b>，能带来短暂愉悦；</p><p><b>血清素</b>，能帮人放松心情缓解焦虑；</p><p><b>内啡肽</b>，可以改变一个人所有的负面情绪、改变对自我的认知、变得积极向上，甚至可以改变人的外表。<hr></p><h2 id="内啡肽"><a href="#内啡肽" class="headerlink" title="内啡肽"></a>内啡肽</h2><div data-aos="zoom-in-right"><p>三种物质中，内啡肽带来的快乐最持久、最真实、最有意义，但同时它也是最需要付出努力的。</p><p>那么如何刺激增加内啡肽呢？比如慢跑时突破自己的运动极限、爬上山顶看到远处的风景、久别之后又见到心爱的人、期待的事情变成现实，比如聊八卦、吃美食、养宠物、听音乐。</p><p>内啡肽很吝啬，希望你每一次感到快乐都是内啡肽带来的。 </p></div><p><b><s><font color="#DC143C"><center>另外科普一下我的主要快乐物质：钱</center></font></s></b></p>]]></content>
      
      
      <categories>
          
          <category> Junkpiece </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Life </tag>
            
            <tag> Happyness </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
